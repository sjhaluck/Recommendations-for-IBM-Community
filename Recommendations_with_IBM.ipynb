{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations with IBM\n",
    "\n",
    "In this notebook, you will be putting your recommendation skills to use on real data from the IBM Watson Studio platform. \n",
    "\n",
    "\n",
    "You may either submit your notebook through the workspace here, or you may work from your local machine and submit through the next page.  Either way assure that your code passes the project [RUBRIC](https://review.udacity.com/#!/rubrics/2322/view).  **Please save regularly.**\n",
    "\n",
    "By following the table of contents, you will build out a number of different methods for making recommendations that can be used for different situations. \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Exploratory Data Analysis](#Exploratory-Data-Analysis)<br>\n",
    "II. [Rank Based Recommendations](#Rank)<br>\n",
    "III. [User-User Based Collaborative Filtering](#User-User)<br>\n",
    "IV. [Content Based Recommendations (EXTRA - NOT REQUIRED)](#Content-Recs)<br>\n",
    "V. [Matrix Factorization](#Matrix-Fact)<br>\n",
    "VI. [Extras & Concluding](#conclusions)\n",
    "\n",
    "At the end of the notebook, you will find directions for how to submit your work.  Let's get started by importing the necessary libraries and reading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...   \n",
       "1      1314.0       healthcare python streaming application demo   \n",
       "2      1429.0         use deep learning for image classification   \n",
       "3      1338.0          ml optimization using cognitive assistant   \n",
       "4      1276.0          deploy your python model as a restful api   \n",
       "\n",
       "                                      email  \n",
       "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7  \n",
       "1  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b  \n",
       "2  b96a4f2e92d8572034b1e9b28f9ac673765cd074  \n",
       "3  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7  \n",
       "4  f01220c46fc92c6e6b161b1849de11faacd7ccb2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import project_tests as t\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# read in data and eliminate null columns\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# Show df to get an idea of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45993, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate shape of df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5148"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of unique users (not including null values)\n",
    "df['email'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45993.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>908.846477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>486.647866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1151.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1336.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1444.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         article_id\n",
       "count  45993.000000\n",
       "mean     908.846477\n",
       "std      486.647866\n",
       "min        0.000000\n",
       "25%      460.000000\n",
       "50%     1151.000000\n",
       "75%     1336.000000\n",
       "max     1444.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather data about the integer article_ids\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "1  See the forest, see the trees. Here lies the c...   \n",
       "2  Here’s this week’s news in Data Science and Bi...   \n",
       "3  Learn how distributed DBs solve the problem of...   \n",
       "4  This video demonstrates the power of IBM DataS...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live           0  \n",
       "1  Communicating data science: A guide to present...       Live           1  \n",
       "2         This Week in Data Science (April 18, 2017)       Live           2  \n",
       "3  DataLayer Conference: Boost the performance of...       Live           3  \n",
       "4      Analyze NY Restaurant data using Spark in DSX       Live           4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show df_content to get an idea of the data\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate shape of the df_content dataframe\n",
    "df_content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1056.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>523.913826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>303.480641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>523.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>786.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1050.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id\n",
       "count  1056.000000\n",
       "mean    523.913826\n",
       "std     303.480641\n",
       "min       0.000000\n",
       "25%     260.750000\n",
       "50%     523.500000\n",
       "75%     786.250000\n",
       "max    1050.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather information about the article_id in the df_content dataframe\n",
    "df_content.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">Part I : Exploratory Data Analysis</a>\n",
    "\n",
    "Use the dictionary and cells below to provide some insight into the descriptive statistics of the data.\n",
    "\n",
    "`1.` What is the distribution of how many articles a user interacts with in the dataset?  Provide a visual and descriptive statistics to assist with giving a look at the number of times each user interacts with an article.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email\n",
       "0000b6387a0366322d7fbfc6434af145adf7fed1    13\n",
       "001055fc0bb67f71e8fa17002342b256a30254cd     4\n",
       "00148e4911c7e04eeff8def7bbbdaf1c59c2c621     3\n",
       "001a852ecbd6cc12ab77a785efa137b2646505fe     6\n",
       "001fc95b90da5c3cb12c501d201a915e4f093290     2\n",
       "Name: article_id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group the df dataframe by user, then count how many articles interactions for each user\n",
    "article_count = df.groupby('email').count()['article_id']\n",
    "article_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5148.000000\n",
       "mean        8.930847\n",
       "std        16.802267\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         3.000000\n",
       "75%         9.000000\n",
       "max       364.000000\n",
       "Name: article_id, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather summary statistics about total article interactions per user\n",
    "article_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the median and maximum number of user_article interactios below\n",
    "median_val = article_count.median() # 50% of individuals interact with ____ number of articles or fewer.\n",
    "max_views_by_user = article_count.max() # The maximum number of user-article interactions by any 1 user is ______."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_views_by_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the email/id for the user with the most interactions\n",
    "max_reader = article_count[article_count==max_views_by_user].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43.0</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76.0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109.0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213.0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305.0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330.0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338.0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354.0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360.0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423.0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429.0</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431.0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436.0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            title  email\n",
       "article_id              \n",
       "2.0             3      3\n",
       "12.0            7      7\n",
       "14.0            1      1\n",
       "16.0            1      1\n",
       "26.0            1      1\n",
       "28.0            1      1\n",
       "29.0           15     15\n",
       "33.0            1      1\n",
       "43.0           15     15\n",
       "50.0            1      1\n",
       "74.0            1      1\n",
       "76.0            4      4\n",
       "108.0           2      2\n",
       "109.0           4      4\n",
       "120.0           1      1\n",
       "124.0           1      1\n",
       "131.0           1      1\n",
       "164.0           2      2\n",
       "193.0           1      1\n",
       "194.0           1      1\n",
       "210.0           1      1\n",
       "213.0           5      5\n",
       "221.0           1      1\n",
       "223.0           1      1\n",
       "236.0           1      1\n",
       "237.0           3      3\n",
       "241.0           1      1\n",
       "252.0           1      1\n",
       "253.0           1      1\n",
       "283.0           2      2\n",
       "...           ...    ...\n",
       "1304.0          3      3\n",
       "1305.0          7      7\n",
       "1314.0          2      2\n",
       "1330.0          7      7\n",
       "1332.0          1      1\n",
       "1336.0          1      1\n",
       "1338.0          6      6\n",
       "1343.0          2      2\n",
       "1351.0          3      3\n",
       "1354.0          4      4\n",
       "1357.0          1      1\n",
       "1360.0          5      5\n",
       "1364.0          3      3\n",
       "1366.0          2      2\n",
       "1367.0          3      3\n",
       "1368.0          1      1\n",
       "1386.0          2      2\n",
       "1391.0          1      1\n",
       "1393.0          1      1\n",
       "1395.0          1      1\n",
       "1396.0          1      1\n",
       "1423.0          7      7\n",
       "1427.0          1      1\n",
       "1428.0          1      1\n",
       "1429.0         35     35\n",
       "1430.0          2      2\n",
       "1431.0          7      7\n",
       "1432.0          1      1\n",
       "1436.0          6      6\n",
       "1439.0          1      1\n",
       "\n",
       "[135 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate how many interactions that user has with each article\n",
    "df[df['email']==max_reader].groupby('article_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Explore and remove duplicate articles from the **df_content** dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and explore duplicate articles\n",
    "df_content['article_id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm df_content shape before removing duplicates\n",
    "df_content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows that have the same article_id - only keep the first\n",
    "df_content.drop_duplicates(subset='article_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm duplicates were removed from df_content\n",
    "df_content.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use the cells below to find:\n",
    "\n",
    "**a.** The number of unique articles that have an interaction with a user.  \n",
    "**b.** The number of unique articles in the dataset (whether they have any interactions or not).<br>\n",
    "**c.** The number of unique users in the dataset. (excluding null values) <br>\n",
    "**d.** The number of user-article interactions in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the number of unique article_id values with interactions\n",
    "df['article_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5148"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm the number of unique users by email\n",
    "df['email'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_articles = df['article_id'].nunique() # The number of unique articles that have at least one interaction\n",
    "total_articles = df_content.shape[0] # The number of unique articles on the IBM platform\n",
    "unique_users = df['email'].nunique() # The number of unique users\n",
    "user_article_interactions = df.shape[0] # The number of user-article interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Use the cells below to find the most viewed **article_id**, as well as how often it was viewed.  After talking to the company leaders, the `email_mapper` function was deemed a reasonable way to map users to ids.  There were a small number of null values, and it was found that all of these null values likely belonged to a single user (which is how they are stored using the function below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the interactions by article and count total interactions per article\n",
    "read_count = df.groupby('article_id').count().sort_values('email',ascending=False)['email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id\n",
       "1429.0    937\n",
       "1330.0    927\n",
       "1431.0    671\n",
       "1427.0    643\n",
       "1364.0    627\n",
       "Name: email, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the max number of interactions with an article\n",
    "read_count.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_viewed_article_id = str(read_count.index[0]) # The most viewed article in the dataset as a string with one value following the decimal \n",
    "max_views = read_count.max() # The most viewed article in the dataset was viewed how many times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...        1\n",
       "1      1314.0       healthcare python streaming application demo        2\n",
       "2      1429.0         use deep learning for image classification        3\n",
       "3      1338.0          ml optimization using cognitive assistant        4\n",
       "4      1276.0          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No need to change the code here - this will be helpful for later parts of the notebook\n",
    "# Run this cell to map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    '''\n",
    "    maps individual email identities to user_id numbers\n",
    "    \n",
    "    INPUT:\n",
    "    None\n",
    "    \n",
    "    OUTPUT:\n",
    "    None, but it does update the create a new user_id column in the dataframe and deletes the email column\n",
    "    '''\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you have everything right here! Nice job!\n"
     ]
    }
   ],
   "source": [
    "## If you stored all your results in the variable names above, \n",
    "## you shouldn't need to change anything in this cell\n",
    "\n",
    "sol_1_dict = {\n",
    "    '`50% of individuals have _____ or fewer interactions.`': median_val,\n",
    "    '`The total number of user-article interactions in the dataset is ______.`': user_article_interactions,\n",
    "    '`The maximum number of user-article interactions by any 1 user is ______.`': max_views_by_user,\n",
    "    '`The most viewed article in the dataset was viewed _____ times.`': max_views,\n",
    "    '`The article_id of the most viewed article is ______.`': most_viewed_article_id,\n",
    "    '`The number of unique articles that have at least 1 rating ______.`': unique_articles,\n",
    "    '`The number of unique users in the dataset is ______`': unique_users,\n",
    "    '`The number of unique articles on the IBM platform`': total_articles\n",
    "}\n",
    "\n",
    "# Test your dictionary against the solution\n",
    "t.sol_1_test(sol_1_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Rank\">Part II: Rank-Based Recommendations</a>\n",
    "\n",
    "Unlike in the earlier lessons, we don't actually have ratings for whether a user liked an article or not.  We only know that a user has interacted with an article.  In these cases, the popularity of an article can really only be based on how often an article was interacted with.\n",
    "\n",
    "`1.` Fill in the function below to return the **n** top articles ordered with most interactions as the top. Test your function using the tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gathers the article_id for the top 'n' articles\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    top_articles = df.groupby('article_id').count().sort_values('user_id',ascending=False)['user_id']\n",
    "    top_articles = list(top_articles.index[:n].astype(int))\n",
    "    return top_articles # Return the top article ids\n",
    "\n",
    "# finds the titles of the top 'n' articles\n",
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    article_ids = get_top_article_ids(n)\n",
    "    top_articles = list(df[df['article_id'].isin(article_ids)].drop_duplicates(subset='article_id')['title'])\n",
    "    return top_articles # Return the top article titles from df (not df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1429, 1330, 1431, 1427, 1364, 1314, 1293, 1170, 1162, 1304]\n",
      "['healthcare python streaming application demo', 'use deep learning for image classification', 'apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'finding optimal locations of new store using decision optimization']\n"
     ]
    }
   ],
   "source": [
    "# display outputs of top 10 ids and titles\n",
    "print(get_top_article_ids(10))\n",
    "print(get_top_articles(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top_5 looks like the solution list! Nice job.\n",
      "Your top_10 looks like the solution list! Nice job.\n",
      "Your top_20 looks like the solution list! Nice job.\n"
     ]
    }
   ],
   "source": [
    "# Test your function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of your three lists from above\n",
    "t.sol_2_test(get_top_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"User-User\">Part III: User-User Based Collaborative Filtering</a>\n",
    "\n",
    "\n",
    "`1.` Use the function below to reformat the **df** dataframe to be shaped with users as the rows and articles as the columns.  \n",
    "\n",
    "* Each **user** should only appear in each **row** once.\n",
    "\n",
    "\n",
    "* Each **article** should only show up in one **column**.  \n",
    "\n",
    "\n",
    "* **If a user has interacted with an article, then place a 1 where the user-row meets for that article-column**.  It does not matter how many times a user has interacted with the article, all entries where a user has interacted with an article should be a 1.  \n",
    "\n",
    "\n",
    "* **If a user has not interacted with an item, then place a zero where the user-row meets for that article-column**. \n",
    "\n",
    "Use the tests to make sure the basic structure of your matrix matches what is expected by the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    user_item = pd.pivot_table(df, values='title', index=['user_id'], columns=['article_id'], aggfunc=lambda x: int(len(x)>0), fill_value=0)\n",
    "    \n",
    "    return user_item # return the user_item matrix \n",
    "\n",
    "user_item = create_user_item_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have passed our quick tests!  Please proceed!\n"
     ]
    }
   ],
   "source": [
    "## Tests: You should just need to run this cell.  Don't change the code.\n",
    "assert user_item.shape[0] == 5149, \"Oops!  The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"Oops!  The number of articles in the user-article matrix doesn't look right.\"\n",
    "assert user_item.sum(axis=1)[1] == 36, \"Oops!  The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"You have passed our quick tests!  Please proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Complete the function below which should take a user_id and provide an ordered list of the most similar users to that user (from most similar to least similar).  The returned result should not contain the provided user_id, as we know that each user is similar to him/herself. Because the results for each user here are binary, it (perhaps) makes sense to compute similarity as the dot product of two users. \n",
    "\n",
    "Use the tests to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>15.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>18.0</th>\n",
       "      <th>...</th>\n",
       "      <th>1434.0</th>\n",
       "      <th>1435.0</th>\n",
       "      <th>1436.0</th>\n",
       "      <th>1437.0</th>\n",
       "      <th>1439.0</th>\n",
       "      <th>1440.0</th>\n",
       "      <th>1441.0</th>\n",
       "      <th>1442.0</th>\n",
       "      <th>1443.0</th>\n",
       "      <th>1444.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0     2.0     4.0     8.0     9.0     12.0    14.0    15.0    \\\n",
       "user_id                                                                      \n",
       "1                0       0       0       0       0       0       0       0   \n",
       "2                0       0       0       0       0       0       0       0   \n",
       "3                0       0       0       0       0       1       0       0   \n",
       "4                0       0       0       0       0       0       0       0   \n",
       "5                0       0       0       0       0       0       0       0   \n",
       "\n",
       "article_id  16.0    18.0     ...    1434.0  1435.0  1436.0  1437.0  1439.0  \\\n",
       "user_id                      ...                                             \n",
       "1                0       0   ...         0       0       1       0       1   \n",
       "2                0       0   ...         0       0       0       0       0   \n",
       "3                0       0   ...         0       0       1       0       0   \n",
       "4                0       0   ...         0       0       0       0       0   \n",
       "5                0       0   ...         0       0       0       0       0   \n",
       "\n",
       "article_id  1440.0  1441.0  1442.0  1443.0  1444.0  \n",
       "user_id                                             \n",
       "1                0       0       0       0       0  \n",
       "2                0       0       0       0       0  \n",
       "3                0       0       0       0       0  \n",
       "4                0       0       0       0       0  \n",
       "5                0       0       0       0       0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_users(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    \n",
    "    '''\n",
    "    # compute similarity of each user to the provided user\n",
    "    similarity = user_item.loc[user_item.index != user_id,:].dot(user_item.loc[user_id,:])\n",
    "    # sort by similarity\n",
    "    similarity.sort_values(ascending=False, inplace=True)\n",
    "    # create list of just the ids\n",
    "    most_similar_users = list(similarity.index)\n",
    "       \n",
    "    return most_similar_users # return a list of the users in order from most to least similar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [3933, 23, 3782, 203, 4459, 3870, 131, 4201, 46, 3697]\n",
      "The 5 most similar users to user 3933 are: [1, 3782, 23, 203, 4459]\n",
      "The 3 most similar users to user 46 are: [4201, 3782, 23]\n"
     ]
    }
   ],
   "source": [
    "# Do a spot check of your function\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now that you have a function that provides the most similar users to each user, you will want to use these users to find articles you can recommend.  Complete the functions below to return the articles you would recommend to each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    gathers the names of the articles with given id numbers\n",
    "    \n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    # gathers the names of articles for any article id that is included in the list of article ids\n",
    "    article_names = list(df[df['article_id'].isin(article_ids)].drop_duplicates(subset='article_id')['title'])\n",
    "    \n",
    "    return article_names # Return the article names associated with list of article ids\n",
    "\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''    \n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    # gathers all of the article ids with which the user has already interacted\n",
    "    article_ids = list(user_item.columns[np.where(user_item.loc[user_id,:])].astype(str))\n",
    "    # gets the article names for those same articles\n",
    "    article_names = get_article_names(article_ids)\n",
    "    \n",
    "    return article_ids, article_names # return the ids and names\n",
    "\n",
    "\n",
    "def user_user_recs(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    '''\n",
    "    # create an empty set to store the recommendations\n",
    "    recs = set()\n",
    "    # gather the article ids for the previous articles from our target user\n",
    "    user_articles = get_user_articles(user_id)[0]\n",
    "    # identify all similar users, ranked from most similar\n",
    "    similar_users = find_similar_users(user_id)\n",
    "    # for each user in the similarity list\n",
    "    for sim_user in similar_users:\n",
    "        # gather the article ides for the previous articles for this particular similar user\n",
    "        sim_user_articles = get_user_articles(sim_user)[0]\n",
    "        # find the new articles that our target user had not read yet\n",
    "        new_articles = np.setdiff1d(sim_user_articles, user_articles)\n",
    "        # for each of the new items to recommend\n",
    "        for item in new_articles:\n",
    "            # if there are already enough recommendations\n",
    "            if len(recs) >= m:\n",
    "                # stop looking for more recommendations\n",
    "                break\n",
    "            # otherwise, if there are not enough recommendations yet\n",
    "            else:\n",
    "                # add the item to the set of recommendations\n",
    "                recs.add(item)\n",
    "        # at the end of a similar user, if there are enough recommendations, stop looking at other users\n",
    "        if len(recs) >= m:\n",
    "                break\n",
    "        \n",
    "    return list(recs) # return your recommendations for this user_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['analyze energy consumption in buildings',\n",
       " 'analyze accident reports on amazon emr spark',\n",
       " '520    using notebooks with pixiedust for fast, flexi...\\nName: title, dtype: object',\n",
       " '1448    i ranked every intro to data science course on...\\nName: title, dtype: object',\n",
       " 'data tidying in data science experience',\n",
       " 'airbnb data for analytics: vancouver listings',\n",
       " 'recommender systems: approaches & algorithms',\n",
       " 'airbnb data for analytics: mallorca reviews',\n",
       " 'analyze facebook data using ibm watson and watson studio',\n",
       " 'a tensorflow regression model to predict house values']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Results\n",
    "get_article_names(user_user_recs(1, 10)) # Return 10 recommendations for user 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you passed all of our tests!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Test your functions here - No need to change this code - just run this cell\n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"If this is all you see, you passed all of our tests!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Now we are going to improve the consistency of the **user_user_recs** function from above.  \n",
    "\n",
    "* Instead of arbitrarily choosing when we obtain users who are all the same closeness to a given user - choose the users that have the most total article interactions before choosing those with fewer article interactions.\n",
    "\n",
    "\n",
    "* Instead of arbitrarily choosing articles from the user where the number of recommended articles starts below m and ends exceeding m, choose articles with the articles with the most total interactions before choosing those with fewer total interactions. This ranking should be  what would be obtained from the **top_articles** function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    sorts users by similarity to target user and total activity so that collaborative filtering is as productive as possible\n",
    "    \n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "                    \n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where \n",
    "                    highest of each is higher in the dataframe\n",
    "     \n",
    "    '''\n",
    "    # create a matrix that measures similiarity\n",
    "    sim_rating = pd.DataFrame(user_item.loc[user_item.index != user_id,:].dot(user_item.loc[user_id,:]), columns=['sim'])\n",
    "    # count the total interactions for each user (measure of level of activity)\n",
    "    interaction_count = pd.DataFrame(df.loc[df.user_id != user_id,:].groupby('user_id').count()['article_id'])\n",
    "    # join the similarity ratings with the user interaction cout\n",
    "    neighbors_df = sim_rating.join(interaction_count)  \n",
    "    # rename the interaction count appropriately\n",
    "    neighbors_df.rename(columns={'article_id':'interactions'}, inplace=True)\n",
    "    # change the name of the index\n",
    "    neighbors_df.index.name = 'neighbor_id'\n",
    "    # sort the values by similarity and then by the number of user_interactions\n",
    "    neighbors_df.sort_values(by=['sim','interactions'],ascending=False, inplace=True)\n",
    "    \n",
    "    return neighbors_df # Return the dataframe specified in the doc_string\n",
    "\n",
    "\n",
    "def user_user_recs_part2(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions \n",
    "    before choosing those with fewer total interactions. \n",
    "   \n",
    "    '''\n",
    "    # create an empty set for the recommendations\n",
    "    recs = []\n",
    "    # gather the 1000 most popular article ids for use ranking\n",
    "    top_articles = df[\"article_id\"].value_counts().index.tolist()\n",
    "    # gets the articles already read by the target user\n",
    "    user_articles = get_user_articles(user_id)[0]\n",
    "    # gathers a list of users similar to the target user (sorted by similarity and level of activity)\n",
    "    similar_users = get_top_sorted_users(user_id).index\n",
    "    # go through each individual user\n",
    "    for sim_user in similar_users:\n",
    "        # get the similar user's articles\n",
    "        sim_user_articles = get_user_articles(sim_user)[0]\n",
    "        # gather only articles new to the target user\n",
    "        new_articles = set(np.setdiff1d(sim_user_articles, user_articles))\n",
    "        # create a list of the new articles\n",
    "        new_list = [x for x in top_articles if str(float(x)) in new_articles]\n",
    "        # keep adding articles to the recommendations until we reach the recommendation limit\n",
    "        for item in new_list:\n",
    "            if len(recs) >= m:\n",
    "                break\n",
    "            else:\n",
    "                recs.append(float(item))\n",
    "                user_articles.append(float(item))\n",
    "        if len(recs) >= m:\n",
    "                break\n",
    "    \n",
    "    # find all of the names of the articles\n",
    "    rec_names  = get_article_names(recs)\n",
    "    \n",
    "    return recs, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 recommendations for user 20 are the following article ids:\n",
      "[1330.0, 1427.0, 1364.0, 1170.0, 1162.0, 1304.0, 1351.0, 1160.0, 1354.0, 1368.0]\n",
      "\n",
      "The top 10 recommendations for user 20 are the following article names:\n",
      "['apache spark lab, part 1: basic concepts', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'putting a human face on machine learning', 'gosales transactions for logistic regression model', 'insights from new york car accident reports', 'model bike sharing data with spss', 'analyze accident reports on amazon emr spark', 'movie recommender system with spark machine learning']\n"
     ]
    }
   ],
   "source": [
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "rec_ids, rec_names = user_user_recs_part2(20, 10)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Use your functions from above to correctly fill in the solutions to the dictionary below.  Then test your dictionary against the solution.  Provide the code you need to answer each following the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tests with a dictionary of results\n",
    "user1_most_sim = find_similar_users(1)[0] # Find the user that is most similar to user 1 \n",
    "user131_10th_sim = find_similar_users(131)[9] # Find the 10th most similar user to user 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This all looks good!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "## Dictionary Test Here\n",
    "sol_5_dict = {\n",
    "    'The user that is most similar to user 1.': user1_most_sim, \n",
    "    'The user that is the 10th most similar to user 131': user131_10th_sim,\n",
    "}\n",
    "\n",
    "t.sol_5_test(sol_5_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` If we were given a new user, which of the above functions would you be able to use to make recommendations?  Explain.  Can you think of a better way we might make recommendations?  Use the cell below to explain a better method for new users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommendations for a new user would behave just like a veteran user, but the similarity between the new user and all other users would be 0. This would default to pulling the most read articles from the most interactive users first. This would allow us to use `user_user_recs_part2` in the same way we use it for veteran users. The problem with this method is that the user does not exist yet, so the functions called by `user_user_recs_part2` will thrown an error until the user is officially introducted into the data and processed.**\n",
    "\n",
    "**Alternatively, we could just pull the top articles using `get_top_articles` without any consideration for what the most interactive users are doing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7.` Using your existing functions, provide the top 10 recommended articles you would provide for the a new user below.  You can test your function against our thoughts to make sure we are all on the same page with how we might make a recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1429.0',\n",
       " '1330.0',\n",
       " '1431.0',\n",
       " '1427.0',\n",
       " '1364.0',\n",
       " '1314.0',\n",
       " '1293.0',\n",
       " '1170.0',\n",
       " '1162.0',\n",
       " '1304.0']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user = '0.0'\n",
    "\n",
    "# What would your recommendations be for this new user '0.0'?  As a new user, they have no observed articles.\n",
    "# Provide a list of the top 10 article ids you would give to \n",
    "new_user_recs = [str(float(x)) for x in get_top_article_ids(10)] # Your recommendations here\n",
    "\n",
    "new_user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "assert set(new_user_recs) == set(['1314.0','1429.0','1293.0','1427.0','1162.0','1364.0','1304.0','1170.0','1431.0','1330.0']), \"Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\n",
    "\n",
    "print(\"That's right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Content-Recs\">Part IV: Content Based Recommendations (EXTRA - NOT REQUIRED)</a>\n",
    "\n",
    "Another method we might use to make recommendations is to perform a ranking of the highest ranked articles associated with some term.  You might consider content to be the **doc_body**, **doc_description**, or **doc_full_name**.  There isn't one way to create a content based recommendation, especially considering that each of these columns hold content related information.  \n",
    "\n",
    "`1.` Use the function body below to create a content based recommender.  Since there isn't one right answer for this recommendation tactic, no test functions are provided.  Feel free to change the function inputs if you decide you want to try a method that requires more input values.  The input values are currently set with one idea in mind that you may use to make content based recommendations.  One additional idea is that you might want to choose the most popular recommendations that meet your 'content criteria', but again, there is a lot of flexibility in how you might make these recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_full_title(title, df_content=df_content):\n",
    "    '''\n",
    "    takes a title and then finds the complete title from the df_content dataframe\n",
    "    \n",
    "    INPUT:\n",
    "    title - (string) the title of an article as it currently exists\n",
    "    \n",
    "    OUTPUT:\n",
    "    true_title - returns the true title as identified in the df_content dataframe\n",
    "    OR\n",
    "    title - returns the title stripped of 3 or more leading digits and 4 spaces and trailing Name and dtype info\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # strip three of more leading digits followed by 4 spaces and remove trailing dataframe information\n",
    "    title = re.sub(\"^[0-9]{3,}\\s{4}\",\"\",title).replace('...\\nName: title, dtype: object','')\n",
    "    # look through every doc_full_name in the df_content dataframe\n",
    "    for true_title in list(df_content['doc_full_name']):\n",
    "        # make sure that all is lowercase for comparison purposes\n",
    "        true_title = true_title.lower()\n",
    "        # if the original title is in the true_title, but it is not already a direct match\n",
    "        # exluding this week in data science, which has multiple matches\n",
    "        if title in true_title and title != true_title and title != 'this week in data science':\n",
    "            # return the full name of the article\n",
    "            return true_title\n",
    "    # otherwise, just return the title of the article\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct article titles in the df dataframe\n",
    "df['title'] = df['title'].apply(lambda x: find_full_title(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate the estimated reading time for each article in the df_content dataframe (based on 250 words per minute)\n",
    "df_content['est_time'] = df_content['doc_body'].apply(lambda x: int(round(len(str(x).split())/250.0,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_content_recs(content_list,time_limit=30,k=10,df_content=df_content, df=df):\n",
    "    '''\n",
    "    a function that provides the most read articles that contain any key search terms or\n",
    "    categories that a user may be interested in\n",
    "    \n",
    "    INPUT:\n",
    "    content_list - (list) a list of strings including content to find (e.g. ['python', 'jupyter', 'spark'])\n",
    "    time_limit - (int) the maximum approximate reading time for the article recommended articles (default: 10)\n",
    "    k - (int) the maximum number of articles to recommend (default: 10)\n",
    "    df - the dataframe of interactions between users and articles\n",
    "    df_content - the dataframe of article information\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a ranked list of the article titles according to the content areas specified in the search\n",
    "    '''\n",
    "    # create a list of the total interactions for each title as defined by the df dataframe\n",
    "    title_interactions = df.groupby('title').count().sort_values(by='user_id', ascending=False)['user_id'].to_dict()\n",
    "    # create an empty dictionary to store the recommendations and their previous interactions\n",
    "    recs = {}\n",
    "    # go through each content term for the user\n",
    "    for content in content_list:\n",
    "        # test if the term is in the doc_description or doc_full_name\n",
    "        test = (df_content['doc_description'].apply(lambda x: content.lower() in str(x).lower()))\n",
    "        test = test | (df_content['doc_full_name'].apply(lambda x: content.lower() in str(x).lower())) \n",
    "        # AND the article that has an estimated reading time less than or equal to the reading limit\n",
    "        test = test & (df_content['est_time'] <= time_limit)\n",
    "        # pull the titles that match the content area and reading limits\n",
    "        titles = df_content[test]['doc_full_name']\n",
    "        # for each matching title\n",
    "        for title in titles:\n",
    "            # if it has previous interactions from df dataframe\n",
    "            if title.lower() in title_interactions.keys():\n",
    "                # create a dictionary entry for that title with the amount of interactions\n",
    "                recs[title.lower()] = title_interactions[title.lower()]\n",
    "            # if the article is not found to have previous interactions\n",
    "            else:\n",
    "                # create a dictionary entry for that title with 0 interactions\n",
    "                recs[title.lower()] = 0\n",
    "    # rank the recommendations over all content areas by the number of interactions\n",
    "    recs = dict(sorted(recs.items(), key=lambda item: item[1], reverse=True))\n",
    "    # return the k top recommendations across all content areas\n",
    "    return list(recs.keys())[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['getting started with python',\n",
       " 'using brunel in ipython/jupyter notebooks',\n",
       " 'discover hidden facebook usage insights',\n",
       " 'pixiedust 1.0 is here! – ibm watson data lab',\n",
       " 'introducing streams designer',\n",
       " 'analyzing streaming data from kafka topics',\n",
       " 'jupyter notebooks with scala, python, or r kernels',\n",
       " 'apple, ibm add machine learning to partnership with watson-core ml coupling',\n",
       " 'excel files: loading from object storage — python',\n",
       " 'variational auto-encoder for \"frey faces\" using keras']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_content_recs(['watson','python'],time_limit=3,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now that you have put together your content-based recommendation system, use the cell below to write a summary explaining how your content based recommender works.  Do you see any possible improvements that could be made to your function?  Is there anything novel about your content based recommender?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The content-based recommendation function takes a list of keywords from the user, a reading time limit, and a number of articles. The system then find articles that have the keywords in their titles or descriptions and that meet the users reading time limit requirements and ranks them based on previous user interactions with the articles. The function then returns the appropriate number of the most popular articles that match the users keyword and reading time limit criteria.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use your content-recommendation system to make recommendations for the below scenarios based on the comments.  Again no tests are provided here, because there isn't one right answer that could be used to find these content based recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep learning with tensorflow course by big data university',\n",
       " 'rapidly build machine learning flows with dsx',\n",
       " 'the machine learning database',\n",
       " 'tensorflow quick tips',\n",
       " 'deep learning with data science experience',\n",
       " 'building your first machine learning system ',\n",
       " 'how to map usa rivers using ggplot2',\n",
       " 'using machine learning to predict value of homes on airbnb',\n",
       " 'machine learning exercises in python, part 1',\n",
       " 'developing for the ibm streaming analytics service']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make recommendations for a brand new user\n",
    "# set content to \"new user\" default values\n",
    "new_content = ['learn','tutorial','introduction']\n",
    "make_content_recs(new_content, time_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep learning with tensorflow course by big data university',\n",
       " 'jupyter notebook tutorial',\n",
       " 'python machine learning: scikit-learn tutorial',\n",
       " 'introducing ibm watson studio ',\n",
       " 'working interactively with rstudio and notebooks in dsx',\n",
       " 'rapidly build machine learning flows with dsx',\n",
       " 'the pandas data analysis library',\n",
       " 'the machine learning database',\n",
       " 'learn tensorflow and deep learning together and now!',\n",
       " 'real-time sentiment analysis of twitter hashtags with spark (+ pixiedust)']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a recommendations for a user who only has interacted with article id '1427.0'\n",
    "# set content to the words in the title of article 1427.0\n",
    "content_1427 = df[df['article_id']==1427.0].head(1)['title'].values[0].split()\n",
    "make_content_recs(content_1427)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Matrix-Fact\">Part V: Matrix Factorization</a>\n",
    "\n",
    "In this part of the notebook, you will use matrix factorization to make article recommendations to the users on the IBM Watson Studio platform.\n",
    "\n",
    "`1.` You should have already created a **user_item** matrix above in **question 1** of **Part III** above.  This first question here will just require that you run the cells to get things set up for the rest of **Part V** of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix here\n",
    "user_item_matrix = pd.read_pickle('user_item_matrix.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>1004.0</th>\n",
       "      <th>1006.0</th>\n",
       "      <th>1008.0</th>\n",
       "      <th>101.0</th>\n",
       "      <th>1014.0</th>\n",
       "      <th>1015.0</th>\n",
       "      <th>1016.0</th>\n",
       "      <th>...</th>\n",
       "      <th>977.0</th>\n",
       "      <th>98.0</th>\n",
       "      <th>981.0</th>\n",
       "      <th>984.0</th>\n",
       "      <th>985.0</th>\n",
       "      <th>986.0</th>\n",
       "      <th>990.0</th>\n",
       "      <th>993.0</th>\n",
       "      <th>996.0</th>\n",
       "      <th>997.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0  100.0  1000.0  1004.0  1006.0  1008.0  101.0  1014.0  1015.0  \\\n",
       "user_id                                                                         \n",
       "1           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "2           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "3           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "4           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "5           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "\n",
       "article_id  1016.0  ...    977.0  98.0  981.0  984.0  985.0  986.0  990.0  \\\n",
       "user_id             ...                                                     \n",
       "1              0.0  ...      0.0   0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "2              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3              0.0  ...      1.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "5              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "article_id  993.0  996.0  997.0  \n",
       "user_id                          \n",
       "1             0.0    0.0    0.0  \n",
       "2             0.0    0.0    0.0  \n",
       "3             0.0    0.0    0.0  \n",
       "4             0.0    0.0    0.0  \n",
       "5             0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick look at the matrix\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` In this situation, you can use Singular Value Decomposition from [numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html) on the user-item matrix.  Use the cell to perform SVD, and explain why this is different than in the previous lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SVD on the User-Item Matrix Here\n",
    "\n",
    "u, s, vt = np.linalg.svd(user_item_matrix) # use the built in to get the three matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is different than the previous lesson because the previous lesson consisted of rating values (1-10) for each movie and maintained a null/nan value until that user had watched a particular movie. This produced richer data on which to calculate the weight of latent features and allowed us to take movies that the user had not watched and make predictions of how much the user would like an unseen movie by using FunkSVD.**\n",
    "\n",
    "**In the context of the users and IBM articles, we just have binary values that track interaction between the articles and the users. The binary nature of this application fills in every cell with a value to represent the interaction with the article or lack thereof. This means there are no null/nan values on which to apply FunkSVD, so we cannot predict if or when a user may interact with an article in the future. The completeness of the table also means that the U, S, and Vt matrices are calculated to produce current read or unread states, so there is no way to apply them to predict future read/unread states.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now for the tricky part, how do we choose the number of latent features to use?  Running the below cell, you can see that as the number of latent features increases, we obtain a lower error rate on making predictions for the 1 and 0 values in the user-item matrix.  Run the cell below to get an idea of how the accuracy improves as we increase the number of latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb2c1877f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "    \n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` From the above, we can't really be sure how many features to use, because simply having a better way to predict the 1's and 0's of the matrix doesn't exactly give us an indication of if we are able to make good recommendations.  Instead, we might split our dataset into a training and test set of data, as shown in the cell below.  \n",
    "\n",
    "Use the code from question 3 to understand the impact on accuracy of the training and test sets of data with different numbers of latent features. Using the split below: \n",
    "\n",
    "* How many users can we make predictions for in the test set?  \n",
    "* How many users are we not able to make predictions for because of the cold start problem?\n",
    "* How many articles can we make predictions for in the test set?  \n",
    "* How many articles are we not able to make predictions for because of the cold start problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.head(40000)\n",
    "df_test = df.tail(5993)\n",
    "\n",
    "def create_test_and_train_user_item(df_train, df_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df_train - training dataframe\n",
    "    df_test - test dataframe\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item_train - a user-item matrix of the training dataframe \n",
    "                      (unique users for each row and unique articles for each column)\n",
    "    user_item_test - a user-item matrix of the testing dataframe \n",
    "                    (unique users for each row and unique articles for each column)\n",
    "    test_idx - all of the test user ids\n",
    "    test_arts - all of the test article ids\n",
    "    \n",
    "    '''\n",
    "    user_item_train = pd.pivot_table(df_train, values='title', index=['user_id'], columns=['article_id'], aggfunc=lambda x: int(len(x)>0), fill_value=0)\n",
    "    user_item_test = pd.pivot_table(df_test, values='title', index=['user_id'], columns=['article_id'], aggfunc=lambda x: int(len(x)>0), fill_value=0)\n",
    "    test_idx = user_item_test.index.values\n",
    "    test_arts = user_item_test.columns\n",
    "    \n",
    "    return user_item_train, user_item_test, test_idx, test_arts\n",
    "\n",
    "user_item_train, user_item_test, test_idx, test_arts = create_test_and_train_user_item(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(user_item_test.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(user_item_test.index.values) - set(user_item_train.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(user_item_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(user_item_test.columns) - set(user_item_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome job!  That's right!  All of the test movies are in the training data, but there are only 20 test users that were also in the training set.  All of the other users that are in the test set we have no data on.  Therefore, we cannot make predictions for these users using SVD.\n"
     ]
    }
   ],
   "source": [
    "# Replace the values in the dictionary below\n",
    "a = 662 \n",
    "b = 574 \n",
    "c = 20 \n",
    "d = 0 \n",
    "\n",
    "\n",
    "sol_4_dict = {\n",
    "    'How many users can we make predictions for in the test set?': c, \n",
    "    'How many users in the test set are we not able to make predictions for because of the cold start problem?': a, \n",
    "    'How many movies can we make predictions for in the test set?': b,\n",
    "    'How many movies in the test set are we not able to make predictions for because of the cold start problem?': d\n",
    "}\n",
    "\n",
    "t.sol_4_test(sol_4_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Now use the **user_item_train** dataset from above to find U, S, and V transpose using SVD. Then find the subset of rows in the **user_item_test** dataset that you can predict using this matrix decomposition with different numbers of latent features to see how many features makes sense to keep based on the accuracy on the test data. This will require combining what was done in questions `2` - `4`.\n",
    "\n",
    "Use the cells below to explore how well SVD works towards making predictions for recommendations on the test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit SVD on the user_item_train matrix\n",
    "u_train, s_train, vt_train = np.linalg.svd(user_item_train) # fit svd similar to above then use the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a subset of the items from the U matrix that are represented in the user_item_test matrix\n",
    "u_test_subset = u_train[[x in test_idx for x in user_item_train.index.values],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 714)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate size of the V transpose matrix\n",
    "vt_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow the V transpose matrix to only those articles that are represented in the user_item_test matrix\n",
    "vt_test_subset= vt_train[:,[x in test_arts for x in user_item_train.columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 574)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm the change in size\n",
    "vt_test_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl4VOXZ+PHvnZmsEHaUnaCgiBsqgrjgrrgB7uJutbztK0p9q6/a11q1tdpqq/Wn1aqlaF0QtSpaFETBvUJAXNgkIEIISAwkJGSdzP374zkZhjBJJstkksz9ua5zZc5+n0ly7nOe55znEVXFGGOMAUiKdwDGGGPaDksKxhhjQiwpGGOMCbGkYIwxJsSSgjHGmBBLCsYYY0IsKRhTBxGZISK/i9O+RUT+ISLbRWRRPGIwicmSQhyIyELvnz013rG0JyKyXkR+EJFOYdOuE5GFcQwrVo4FTgUGqOro2jNF5GoR+bixGxWRE0QktyUC9LZ3l4g818Ay60WkTERKwoZ+zdxvix6H2cWSQisTkSzgOECBCa28b39r7i9G/MC0eAfRWCLia+Qqg4H1qrozFvHEwTmq2jlsyItnMB3kfyEmLCm0viuB/wAzgKvCZ4hIuoj8SUS+F5EiEflYRNK9eceKyKciUigiG0Xkam/6QhG5Lmwbu11BioiKyPUisgZY4037i7eNHSKyRESOC1veJyK/EpG1IlLszR8oIo+JyJ9qxfumiPyi9gGKyBMi8mCtaW+IyP94n28VkU3e9leLyMmN+P4eAG4WkW4R9pvlHa8/bFro+/G+m09E5CHve1wnIkd70zeKyFYRuarWZnuJyLterB+IyOCwbQ/35m3zjuOisHkzRORxEZkjIjuBEyPE209EZnvr54jIT73p1wJPA2O9q+q7G/H9ICLXiMhKL+Z1IvJf3vROwNtAv/ArdhFJEpHbvN95gYjMEpEetb7Tq0Rkg4j8KCL/580bD/wKuNjb1peNidPbxlFhf9dfisgJzTiO3Yr7pNbdhLg7lltF5Ctgp4j4vfVeFZF8EflORG4MW360iGR7/yc/iMifG3t87ZKq2tCKA5AD/DdwBFAF7B027zFgIdAf8AFHA6nAIKAYmAwkAz2Bkd46C4HrwrZxNfBx2LgC7wI9gHRv2uXeNvzAL4EtQJo37xbga2B/QIBDvWVHA3lAkrdcL6A0PP6wfY4DNgLijXcHyoB+3nY3Av28eVnAvlF+d+uBU4B/Ab/zpl0HLAzblgL+sHVC34/33QSAa7zv93fABu97TwVO877nzt7yM7zxcd78v9R8t0An7ziu8b7Hw4EfgQPD1i0CjsFdfKVFOJ4PgL8CacBIIB84OdLvMcK6dc4HzgL29X5/x3u/p8O9eScAubWW/wXuQmWAd5x/A16s9Z0+BaR7fw8VwAHe/LuA56L5vUWY3h8oAM70vqNTvfHeTTyOGTV/F5GW8eJYBgz0jiUJWALcCaQA+wDrgNO95T8DrvA+dwaOivf5ozWGuAeQSAOunLgK6OWNrwJu8j4n4U6ch0ZY73bgtTq2uZCGk8JJDcS1vWa/wGpgYh3LrQRO9T5PBebUsZzgTrbjvPGfAu97n4cCW3En9+RGfn/rvfUOwp1we9P4pLAmbN7B3vLhibmAXQl3BjAzbF5noNo7qVwMfFQrvr8Bvwlb99l6jmWgt63MsGn3ATMi/R4jrF/v/FrLvg5M8z6fwJ4n05V4ycgb7+v9nfrDvtMBYfMXAZd4n+8iuqRQAhR6w+ve9FuBf9Zadi5wVROPYwYNJ4WfhI2PATZE+F/7h/f5Q+BuvP/XRBms+Kh1XQXMU9UfvfEX2FWE1At3xbg2wnoD65gerY3hIyLyS++2vEhECoGu3v4b2tczuLsMvJ//jLSQuv+ombg7G4BLgee9eTm4K9O7gK0iMlMaWemoqt8AbwG3NWY9zw9hn8u87dWe1jlsPPTdqWoJsA13xzMYGOMVexR63+NlQJ9I60bQD9imqsVh077HXT03i4icISL/8YqlCnFX4r3qWWUw8FrYcazEJay9w5bZEva5lN2/o2hMUtVu3jApbL8X1voOj8UlpaYcRzTCfyeDcUVQ4fv/FbuO+1pgP2CViCwWkbObue92wSpbWom4uoGLAJ+I1PyDpQLdRORQXJFNOe52uXbZ7EZc8U0kO4GMsPE+EZYJNYUrrv7gVuBkYLmqBkVkO+7qvmZf+wLfRNjOc8A3XrwH4K7c6vIiME9E7sddkZ0bCkb1BeAFEemCu7r+A3BFPduK5DfAUiC8nqOmUjYD2OF9jvR9NMbAmg8i0hlXDJeH+54+UNVT61m3viaI84AeIpIZlhgGAZuaE6y4J9pexdVdvaGqVSLyOrt+v5Fi2oi7gv4kwvayGthlc5pZ3oi7U/hphP025Tga9b/g7f87VR0WKThVXQNMFpEk4DzgFRHpqR2n8j8iu1NoPZNwV18jcOXHI3En1o+AK1U1CEwH/uxVfvlEZKz3z/E8cIqIXORVjvUUkZHedpcB54lIhogMxV3d1CcTV66eD/hF5E6gS9j8p4HfisgwcQ4RkZ4AqpoLLMbdIbyqqmV17URVv/D28TQwV1ULAURkfxE5yTuuctyVeXXDX98e288BXgJuDJuWjzupXu59fz/BJbjmOFNcJX8K8Fvgc1XdiLtT2U9ErhCRZG84UkQOiDL+jcCnwH0ikiYih+B+d883Ijbx1g0NuLLxVNx3HxCRM3B1JTV+AHqKSNewaU8A94pXiS4ivUVkYpQx/ABkeSfOxnoOOEdETvd+X2le5fCAJh7HMtzvq4eI9MHdkdZnEbDDq3xO92I4SESOBBCRy0Wkt/e/Weit0+i/1fbGkkLruQpXVrlBVbfUDMCjwGXinpi5GXfHsBhXTPEHXMXuBtyt8y+96ctwFX4ADwGVuH+SZ2j4pDIX9+TGt7jiinJ2v6X+MzALmIe72v47rlKuxjO4sviIRUe1vIirA3ghbFoqcD+uUnYLsBfulh0RuUxElkex3Rr34Cp8w/0UV1leAByIO/E2xwu4u5JtuIcDLgPwru5PAy7BXfVvwf2+GvPuyWRcmX0e8BquPuLdRqx/NC6p1h5uxP0Ot+OK7mbXrKCqq3C/l3VekUk/XAX6bNydXTGu0nlMlDG87P0sEJGljYi9JjFOxP3+83F/h7fg/uaLm3Ac/8TdZa/H/f2+1MD+q4FzcBdo3+H+Jp/GFacCjAeWi0gJ7ju6RFXLG3OM7VHN0yHGREVExuGu8LK8KyhjTAdidwomaiKSjHtx7GlLCMZ0TJYUTFS8svJC3JMhD8c5HGNMjFjxkTHGmBC7UzDGGBPS7t5T6NWrl2ZlZcU7DGOMaVeWLFnyo6r2bmi5dpcUsrKyyM7OjncYxhjTrojI99EsZ8VHxhhjQiwpGGOMCbGkYIwxJsSSgjHGmJCYJQURmS6uJ6tIrW3WdEz+iLgep74SkcNjFYsxxpjoxPJOYQauQam6nAEM84YpwOMxjMUYY0wUYpYUVPVDXMuSdZmI65lKVfU/uH4F+sYqHmOMMQ2L53sK/dm9yeZcb9rm2guKyBTc3QSDBg1qleCMMSYmgkEIlEFlKVTthMqd3udSCFS4eVXl3ng5VFd6QxXsdzr0PyKm4cUzKUiEaREbYlLVJ4EnAUaNGmWNNRljWkd1AMoLobIEqsrcUFkC5UVuqChxJ++qMvezssQ7ye+E8h1QscNNC1S4ZQLeyb6pOu/doZNCLmFdHQIDcJ2NGGNMywgG3Um4ohhKfvCGrWEn9R27Tt4VO8Ku2ndCWRFUFEW5I4HkdEjpDCmd3M+0LtClnxv3p0NyGvjT3HhyhhtSOu0a/Gne9LTdP/tSwZcMSX6QSNfSLSueSWE2MFVEZuJ6eSpS1T2KjowxCay6Csq2Q+k2KC2AnfluKC/0iloq3Em/tAB2/ghlhbtfrVfV152yQGompHZxJ/DUTEjrCpl93Uk6rSuk94CMHu4kn5y+68Sf1tUNKZ0hJcOdxFvhhN0aYpYURORF4ASgl4jk4ro0TAZQ1SeAObguJnOAUuCaWMVijGmDgkF35V6UC9vX7xp25ELxD1CyxSWE+vhS3Uk5oydk9IJuA3edqJM7QWrYlXvnvaBzH/czvRukZEKSvapVW8ySgqpObmC+AtfHav/GmDZA1Z3Yt6+H7d/B1lWwdYUbCjdCsGr35Tv3ga4DoOe+kHUMdNrLXamnd3c/O+3lTuppXcGX0mGuztuSdtdKqjGmDamucmX0xVugeLO78i/eDNvWQcFa2Pbd7uXykgQ99oU+B8OIiS4BdB0I3QZDt0HuCt/ElSUFY8yeVF3ZfUGOO7EXb3Yn/pItULrdleGX/ujK8fd4aFBcMU7PoTDgSOgxxJ30uw9205LT43FEJkqWFIxJVMEg7NzqinGKNrginh/XuKFgjXs6J1xaN8js48rvew2FjDGuUjazjyv2ydzb/ezUyz0tY9qlhEkK5VXVJPuS8CVZGaRJMNUBKPzeO+F/C/mrYOtKyF+959M5mf3cCf+gC6DXMOg5zF3pd+lnV/gJImGSwsvZG/nj3NUcmdWDMUN6cPjg7vTslEJmWjJd05NJ8dtTCKYdqyx15fiFG7zh+13l+tvX716h22kv2Gs4HH6FK87pOtAV93Qb5B7LNAktYZLC8L5dOPuQfnz+XQHvr9q6x/zeman075bOgO7pDO6ZweAenRjQI51Uvw9wDzn0yEihT9c00pJ9rR2+MY4q7NgEm5ZC3lLIW+buAHbk7r6cP91d4e81HIaf5U7+vfd3PzN6xCd20y4kTFI4MqsHR2a5f4atO8pZnreDHeVV7CirYntpFXmFZeRuL+ObTUW8880WAsG6W9PolpFMmn9XYvD7hFR/Eql+H5lpfrpnpNC9UwrdM5Lp0SmF7hkp9OicQu/OqeyVmUr3Tikk++zOxEQhUAGbv4LcRbDRG4q9F/+T/LDXCPfoZs+h0GOfXZW6GT3tcU3TJAmTFMLt1SWNvbqk1Tk/UB0kr7Cc3O2lVHnJIahKQUklW4rK2LKjnKqAm64ogaBSEQhSUVXNjvIA634sYdv3lWwvraK6juSSnuyjS7qfrunJLml0SqFLWjJpyUmkJvvISPHRr6u7c+nXLZ0enVPITPUj9o/ecQWr3VV/3heweZm7G9j8JVRXuPldB8Hgo2HgaOg/CvY+0DWDYEwLSsik0BC/L4lBPTMY1LN5z0yrKsUVAbaVVFKws5L84grySyrYvrOS4vIqdpQFKCxzyWNtfglFZVVUBIJUBoKUVVWjtfKJP0nomp5MkldZniTQt2s6WT0zGNQjg/QUP/4kwZck9OycQp8uafTtmk73Tsl0SvGH1jNtxM4C2PAZbPzcJYK8L1wTDeDavelzCIz+qUsCA0ZDF2tZ3sSeJYUYEhG6pCXTJS2ZrF6dGrVuVXWQLUXlbNxeSl5hOYWllWzbWUlRWRU1Nx+B6iB5RWUsXr+dN77M2yOJ7B4LZKb66ZLu4umS7qdzajIZKT46pfpI9fvwJQn+JCHFn0RGip+MFB/pKb5Q0ViKX/AnJYWWyUxLJjPNT+c0P2l+H8k+sTuZulRXwZavXT3Api8gdzH8uNrN86W4l7lGXgr9Dod+h7knf5Ks7sq0PksKbVSyL4mBPTIY2CO6u5VAdZBA0BVlVQWCFOysYHNROZuLyikqraK4vIqisiqKywPsKA+wo8zVo5RWBiipqKYyUE1QIRAMUhEI1ptg6iICKb6k0KO/NXct/iTB5xNSfC65pCYn0TnVTxcvqYTXr7j6GZeIOqX6vGWSyUgNS0412/e5baclu3nJ/qTQPpOTkuJ/Z1RWCDnzYfUcWDN/15u9GT1d88eHXgyDjnZJwIqBTBthSaGD8PuSCNV9p0L3TikM3atpjxeqKuVVQUorA5RWVlNZHaSiKkhldZDqYJBAtVJZHXQJxks0FYFqKgMuoQSCSnVQCQSDVAcJrVPhbaciUE1xeYBNhWUUlwdC9S6qu+pnKgPBZn0fIuyWeDqlenc+yb5Q0vIlCdVhsbppLrHIbtvaldjS/O7OKiPF7+p/vATm97k10ks3sfeWD+m35T165i8iSQNUpvYgv9+pbO87jqo+h+HvPoj0VF9oX76dij+p3EugSfi8ZJcksltdsT/J7sRM7FlSMHsQEdK9oqOecYohGFRKq6rZUVbFjvIqSiurQwmlqlpDJ/PK6l3JqKIqSLW66RVV1RRXBNhRFmBHeRVlldWUVATIL64IJa3qoIaSg0+EoLduVXBXQlJ1g0twLlnurAyE7qS6UcxxSV9zdNJyjk5azuAk97jzumAfXg2ewbzqI1hWPpRgURKsBNfZ4MY9jjcaIoTullL9SaQmJ4XumlqaICTVvtvzhubkpSTZtb3wBJckuISYJMT7Bq8tu3DUQI4Z2ium+7CkYNqkpCShc6qfzql++tG23qTV7esJLJuFfPsOvs1LEZTqlC6U9x/Lj/2PZueA46nqui/HqXJM2A1PVTBIWWU1pZXVlFVVU+3dSQWqdyWzqmol6BUDVtdKTlXVLvmVV+26e6sIBAk2payvAS5Bend5QSWo6u4Qm3EHp6Htum2FR11zlxioDkbuftEAcOLwvWK+D0sKxkSjrBBWvglfzkS+/9h1DNJ/FJxwGww9BV+/w+iU5KMTENvrOGNiy5KCMXUJVLhK4q9fgTXzXOfpPfaFE+9wlcTdBsU7QmNanCUFY8KpuhfHlr0AX81y3T523huOvM41Etf/cHtT2HRolhSMUYUfvoHlr7lh2zrXzeMBZ8PIy2CfE+ydAZMwLCmYxLWzAL6eBV8855KC+GDIcXD0jXDgJNcFpDEJJqZJQUTGA38BfMDTqnp/rfmDgelAb2AbcLmq5u6xIWNaSnWVe6Fs2fOw+h3XpHTfkXDmg3Dgua6DGGMSWMySgoj4gMeAU4FcYLGIzFbVFWGLPQg8q6rPiMhJwH3AFbGKySSwknxY/BRkT3fdTGb0cu0KjbwM+hwU7+iMaTNieacwGshR1XUAIjITmAiEJ4URwE3e5wXA6zGMxyQaVdi0BJY+A1++5J4e2m88HHEVDD3Fuow0JoJYJoX+7P7qZi4wptYyXwLn44qYzgUyRaSnqhaELyQiU4ApAIMG2WOApgHbv4elz8I3r7hex/xprrG5sde7huaMMXWKZVKI9Nxe7ZcVbwYeFZGrgQ+BTUBgj5VUnwSeBBg1apS98Ggiy18NHz/kHiVFYcjxMO4WGH42pHeLd3TGtAuxTAq5wMCw8QFAXvgCqpoHnAcgIp2B81W1KIYxmY4oNxs+eRhWvuU6lx/zM3dX0LV/vCMzpt2JZVJYDAwTkSG4O4BLgEvDFxCRXsA2VQ0Ct+OeRDKmYcEg5LwLnzwC338Mad1g3M0uIdgTRMY0WcySgqoGRGQqMBf3SOp0VV0uIvcA2ao6GzgBuE9EFFd8dH2s4jEdROVO97bx509AQQ5k9oPTfw+HXwmpTWsq3Bizi2gMWliMpVGjRml2dna8wzCtLVjtXjJbcC+U/OB6KBt7PYyYaE8RGRMFEVmiqqMaWs7eaDZt35r58O6vYesKGDgGLpwBg8ZaG0TGxIAlBdN2/bAc5t0Ba9+HHvvARc/CARMsGRgTQ5YUTNuzbR189GfXFEVqFxh/P4y6Fvwp8Y7MmA7PkoJpO/JXw0d/gq9fhqRk9yTRuFsgo0e8IzMmYVhSMPGX/y188Af45lX3nsFR/w1H3wCZfeIdmTEJx5KCiZ+CtS4ZfP0y+NPhmGkuGdh7BsbEjSUF0/qKcuGDP7pHTP2pLhEcfaMlA2PaAEsKpvVUV8Fnj8LC+0GDrovL434JmXvHOzJjjMeSgmkdeV/A7Btgy9eugbrx91nH98a0QZYUTGxVlcPC++DTR6DTXnDRP2HEhHhHZYypgyUFEzsbF8Mb/w0/fguHXQGn/c6asDamjbOkYFpeeRG8f6/r/jKzH1z+quvpzBjT5llSMC1HFZb/C975lWu07sjr4OQ7Ia1LvCMzxkTJkoJpGdvWwb9/6dop6nsoTH4R+h8e76iMMY1kScE0T3WV6/Xswwdd0xTj/wCjfwpJvnhHZoxpAksKpulKt8GsK2H9R65fg/H3Q5d+8Y7KGNMMlhRM0xSshecvhKKNMOkJGDk53hEZY1qAJQXTeGvfh5evcUVEV86GwWPjHZExpoVYUjDRqw64F9E++hP0Hu4qk3sMiXdUxpgWlBTLjYvIeBFZLSI5InJbhPmDRGSBiHwhIl+JyJmxjMc0w47N8Mw58NGDcNhl8NP3LSEY0wHF7E5BRHzAY8CpQC6wWERmq+qKsMXuAGap6uMiMgKYA2TFKibTRFu+hucvci+lnfskHHpxvCMyxsRILO8URgM5qrpOVSuBmcDEWssoUPNmU1cgL4bxmKZYMx+mj3efr51rCcGYDi6WdQr9gY1h47nAmFrL3AXME5EbgE6AtYXQlmRPh3/fDHuPgEtn2eOmxiSAWN4pSIRpWmt8MjBDVQcAZwL/FJE9YhKRKSKSLSLZ+fn5MQjV7CZYDW/fBm/dBPueBNe8bQnBmAQRy6SQCwwMGx/AnsVD1wKzAFT1MyAN2KP7LVV9UlVHqeqo3r17xyhcA0D5DnjhYvj8cddX8uSZkJoZ76iMMa0klklhMTBMRIaISApwCTC71jIbgJMBROQAXFKwW4F4KdkK/zgT1i2Asx9yHeH47KllYxJJzP7jVTUgIlOBuYAPmK6qy0XkHiBbVWcDvwSeEpGbcEVLV6tq7SIm0xoKN8CzE6F4C1z6kjV1bUyCiulloKrOwT1mGj7tzrDPK4BjYhmDiUL+anh2ElTthCteh0G1nwcwxiQKKxtIdPnfwoyzAIGr50Cfg+IdkTEmjiwpJLJt6+DZCbiE8G/ovV+8IzLGxJklhURVuAGemQCBCksIxpgQSwqJqHiLSwgVO+CqN93LacYYgyWFxFO6zVUql2yFq2a7rjONMcZjSSGRVBTD8xe4uoTLXoYBo+IdkTGmjbGkkCgqiuHFyZC3DC5+DvY5Pt4RGWPaIEsKiWDnj/Dc+a4J7POehOHWbYUxJjJLCh1d4Qb457lQlOt6Stvv9HhHZIxpwywpdGTb1sGMs6GyxL2pbH0pG2MaYEmho6pJCFVl7j2EPgfHOyJjTDsQ0z6aTZxs+w5mnOMSwlWzLSEYY6JmdwodTclW92Ja1U73YpolBGNMI1hS6Eiqq2DWVbAzH37ytiUEY0yjWVLoSOb+CjZ8Cuf/HfodFu9ojDHtkNUpdBRfPA+LnoSxU+HgC+IdjTGmnbKk0BHkZsNbN8GQcXDK3fGOxhjTjllSaO+KcmHmpZDZBy6YYX0qG2OapcGkICJTRaR7awRjGqlyJ7x4CVSWun6VO/WMd0TGmHYumjuFPsBiEZklIuNFRGIdlIlCMAiv/Rf8sBwumA57HRDviIwxHUCDSUFV7wCGAX8HrgbWiMjvRWTfhtb1kshqEckRkdsizH9IRJZ5w7ciUtiEY0hMn/0/WPkmnPpb2O+0eEdjjOkgoiqAVlUVkS3AFiAAdAdeEZF3VfV/I60jIj7gMeBUIBd3tzFbVVeEbfemsOVvAOw5ymjkLoH37oEDJsDY6+MdjTGmA4mmTuFGEVkC/BH4BDhYVX8OHAGcX8+qo4EcVV2nqpXATGBiPctPBl6MOvJEVV4Er1wDmX1hwiNgpXnGmBYUzZ1CL+A8Vf0+fKKqBkXk7HrW6w9sDBvPBcZEWlBEBgNDgPfrmD8FmAIwaNCgKELuoFThzV+4J46ueRvSrf7fGNOyoqlongNsqxkRkUwRGQOgqivrWS/SJazWsewlwCuqWh1ppqo+qaqjVHVU7969owi5g/rin7D8X3Dir2BQxPxqjDHNEk1SeBwoCRvf6U1rSC4wMGx8AJBXx7KXYEVH9du6Cub8Lww5Ho69qeHljTGmCaJJCqKqoSt8VQ0SXbHTYmCYiAwRkRTciX/2HhsX2R9Xcf1ZdCEnoKoyeOUnkNLJdaeZ5It3RMaYDiqapLDOq2xO9oZpwLqGVlLVADAVmAusBGap6nIRuUdEJoQtOhmYGZ54TC3z7oCty+HcJ9yby8YYEyPRXPH/DHgEuANXJ/AeXqVvQ1R1Dq5OInzanbXG74pmWwlr1RxY/LRr6G7YqfGOxhjTwTWYFFR1K67ox7S20m3w1i9g74Ph5N/EOxpjTAJoMCmISBpwLXAgkFYzXVV/EsO4DLj+EUoL4LKXwZ8S72iMMQkgmjqFf+LaPzod+AD3FFFxLIMywLdz4csX4dj/gb6HxjsaY0yCiCYpDFXVXwM7VfUZ4CzA+nmMpbJCeHMa7HUgjLsl3tEYYxJINEmhyvtZKCIHAV2BrJhFZNzTRiVbYdJjVmxkjGlV0Tx99KTXn8IduPcMOgO/jmlUiWzdQvfm8jG/sH6WjTGtrt6kICJJwA5V3Q58COzTKlElqsqdrtiox75wwh4tjRtjTMzVW3zkvb08tZViMQt+D9vXw4T/B8np8Y7GGJOAoqlTeFdEbhaRgSLSo2aIeWSJZtMS+M9f4YhrIOuYeEdjjElQ0dQp1LyPEN6bi2JFSS0nWA1v3QSd94ZT7453NMaYBBbNG81DWiOQhLbkH7D5S9fXclrXeEdjjElg0bzRfGWk6ar6bMuHk4B2/gjv/RaGjIMDz4t3NMaYBBdN8dGRYZ/TgJOBpYAlhZYw/y6oLIEzHrCuNY0xcRdN8dEN4eMi0hXX9IVpro2L3TsJR98Iew2PdzTGGBPV00e1lQLDWjqQhKMKc2+Hzn3g+P+NdzTGGANEV6fwJrv6Vk4CRgCzYhlUQljxBuQuhgmPQmpmvKMxxhggujqFB8M+B4DvVTU3RvEkhkAlvHc39D4ARl4a72iMMSYkmqSwAdisquUAIpIuIlmquj6mkXVkS2bAtnVw6cvW37Ixpk2Jpk7hZSAYNl7tTTNNUV4EH9zvHkG17jWNMW1MNEnBr6qVNSPe56jacxaR8SKyWkRyRCRiC28icpGIrBCR5SLyQnRht2Of/MX1pnbqPfYIqjGmzYmm+ChfRCao6mwAEZkI/NjQSiLiAx4DTgVygcUiMltVV4QtMwy4HThGVbeLyF5NOYh2Y0cefPZXOOgCaxbbGNOoLIYSAAAcDklEQVQmRZMUfgY8LyKPeuO5QMS3nGsZDeSo6joAEZkJTARWhC3zU+Axr2luVHVrtIG3Swt+D1oNJ1t3FMaYtimal9fWAkeJSGdAVDXa/pn7AxvDxnOBMbWW2Q9ARD4BfMBdqvpO7Q2JyBRgCsCgQYOi3H0bs3UlLHsexvwcumfFOxpjjImowToFEfm9iHRT1RJVLRaR7iLyuyi2HanAXGuN+3Evwp0ATAaeFpFue6yk+qSqjlLVUb17945i123Q/LsgJRPG3RzvSIwxpk7RVDSfoaqFNSNeUc+ZUayXCwwMGx8A5EVY5g1VrVLV74DVdMS3pb/7CL59B477H8iwriiMMW1XNEnBJyKpNSMikg6k1rN8jcXAMBEZIiIpwCW4Pp7DvQ6c6G23F644aV00gbcbqu5FtS79Ycx/xTsaY4ypVzQVzc8B74nIP7zxa4BnGlpJVQMiMhWYi6svmK6qy0XkHiDbe5ppLnCaiKzAvf9wi6oWNOVA2qyc+a45i3P+Yl1sGmPaPFGtXcwfYSGR8cApuHqC7UBfVb2+/rViY9SoUZqdnR2PXTeeKjx1IpRugxuWgC853hEZYxKUiCxR1VENLRdtK6lbcG81n4/rT2FlM2JLHN/OhbwvYNwtlhCMMe1CncVHIrIfrh5gMlAAvIS7szixlWJr31Rh4e+h+xA49JJ4R2OMMVGpr05hFfARcI6q5gCIyE2tElVHsHqO63d50uN2l2CMaTfqKz46H1dstEBEnhKRk4n87oGpTRUW3gc99oWDL4p3NMYYE7U6k4KqvqaqFwPDgYXATcDeIvK4iJzWSvG1T6vfhi1fe3UJ0TzgZYwxbUODFc2qulNVn1fVs3EvoC0DIrZ4anB3CR/+0TVlcfCF8Y7GGGMapVF9NKvqNlX9m6qeFKuA2r2c+e6Jo+N+aXcJxph2p1FJwTRAFT74A3QdCIfYE0fGmPbHkkJLWrfQvb187E3gj6ofImOMaVMsKbQUVfjgj5DZDw67PN7RGGNMk1hSaCk582HDp64lVH807QUaY0zbY0mhJQSDMP9u98TR4VfFOxpjjGkyezymJXzzKvzwNZz3tNUlGGPaNbtTaK5AJSz4Hex9MBx0fryjMcaYZrE7heZa+gxsXw+XvQJJlmONMe2bncWao7LUPXE0+BgYekq8ozHGmGazO4XmyP477NwKFz0LYm0FGmPaP7tTaKqKEvj4Ydj3JBg8Nt7RGGNMi7Ck0FSLnoTSH+GEX8U7EmOMaTGWFJqifAd8+ggMOw0GHhnvaIwxpsXENCmIyHgRWS0iOSKyR3PbInK1iOSLyDJvuC6W8bSYz/8GZdvhhNvjHYkxxrSomFU0i4gPeAw4FcgFFovIbFVdUWvRl1R1aqziaHEVJfDZ/4P9z4T+h8c7GmOMaVGxvFMYDeSo6jpVrQRmAhNjuL/W8dVLUF7kWkI1xpgOJpZJoT+wMWw815tW2/ki8pWIvCIiAyNtSESmiEi2iGTn5+fHItboqMKip6DvSBhgdQnGmI4nlkkh0oP7Wmv8TSBLVQ8B5gPPRNqQqj6pqqNUdVTv3r1bOMxGWP8R5K+E0VPsvQRjTIcUy6SQC4Rf+Q8A8sIXUNUCVa3wRp8CjohhPM236ElI7wEHnRfvSIwxJiZimRQWA8NEZIiIpACXALPDFxCRvmGjE4CVMYyneQo3wqp/wxFXQXJ6vKMxxpiYiNnTR6oaEJGpwFzAB0xX1eUicg+QraqzgRtFZAIQALYBV8cqnmbLnu5+jvpJfOMwxpgYimnbR6o6B5hTa9qdYZ9vB9r+w/6BCtca6v5nQrdB8Y7GGGNixt5ojsba96G0AI64Ot6RGGNMTFlSiMby1yCtG+xzQrwjMcaYmLKk0JCqclj9NhxwDviS4x2NMcbElCWFhqx9Hyp2wIGT4h2JMcbEnCWFhix/DdK7w5Dj4x2JMcbEnCWF+ljRkTEmwVhSqM/a96CyGEZY0ZExJjFYUqjP8tdcsxZDxsU7EmOMaRWWFOpSVWZFR8aYhGNJoS4586GyxJ46MsYkFEsKdfnmX5DRC7Ks6MgYkzgsKURSuRO+fQdGTABfTJuHMsaYNsWSQiTfzoWqUjjw3HhHYowxrcqSQiTLX4POe8PgY+IdiTHGtCpLCrVVFMOaeTBiIiT54h2NMca0KksKta1+BwLlcKB1uWmMSTyWFGpb/hpk9oOBY+IdiTHGtDpLCuHKiyDnXfduQpJ9NcaYxGNnvnCr34bqSnvqyBiTsGKaFERkvIisFpEcEbmtnuUuEBEVkVGxjKdBy1+DrgNhwJFxDcMYY+IlZklBRHzAY8AZwAhgsoiMiLBcJnAj8HmsYolKWSHkvOeeOhKJayjGGBMvsbxTGA3kqOo6Va0EZgITIyz3W+CPQHkMY2nY6jkQrLKiI2NMQotlUugPbAwbz/WmhYjIYcBAVX2rvg2JyBQRyRaR7Pz8/JaPFGD5667oqP8Rsdm+Mca0A7Fs2CdSGYyGZookAQ8BVze0IVV9EngSYNSoUdrA4o1Xtt31xXzUz6zoyJhaqqqqyM3Npbw8vjfzJjppaWkMGDCA5OSmNfkfy6SQCwwMGx8A5IWNZwIHAQvFnYj7ALNFZIKqZscwrj2t8oqORljRkTG15ebmkpmZSVZWFmIXTW2aqlJQUEBubi5Dhgxp0jZiWXy0GBgmIkNEJAW4BJhdM1NVi1S1l6pmqWoW8B+g9RMCeE8dDYL+h7f6ro1p68rLy+nZs6clhHZAROjZs2ez7upilhRUNQBMBeYCK4FZqrpcRO4RkQmx2m+jlW6DdQvcC2v2R29MRJYQ2o/m/q5i2lmAqs4B5tSadmcdy54Qy1jqlPMeBAPuUVRjjElw9kbz959Aahfod1i8IzHGRFBYWMhf//rXJq//8MMPU1paWuf8Cy64gHXr1lFaWspZZ53F8OHDOfDAA7nttl3v21ZUVHDxxRczdOhQxowZw/r165scT0uorKxk3LhxBAKBFt+2JYXvP4VBR1kz2ca0UbFMCsuXL6e6upp99tkHgJtvvplVq1bxxRdf8Mknn/D2228D8Pe//53u3buTk5PDTTfdxK233trkeBqjrpN+SkoKJ598Mi+99FKL7zOx+5osyYcfV8PIyfGOxJh24e43l7Mib0eLbnNEvy785pwD65x/2223sXbtWkaOHMmpp57KAw88wAMPPMCsWbOoqKjg3HPP5e6772bnzp1cdNFF5ObmUl1dza9//Wt++OEH8vLyOPHEE+nVqxcLFizYbdvPP/88Eye6ouOMjAxOPPFEwJ10Dz/8cHJzcwF44403uOuuuwB3ZzF16lRUdbfy+4ULF/Lggw/y1lvutaupU6cyatQorr76am677TZmz56N3+/ntNNO48EHHyQ/P5+f/exnbNiwAXDJ65hjjuGuu+4iLy+P9evX06tXL/7v//6Pa665hsrKSoLBIK+++irDhg1j0qRJ3H777Vx22WUt84vwJHZS2PCZ+2k9rBnTZt1///188803LFu2DIB58+axZs0aFi1ahKoyYcIEPvzwQ/Lz8+nXrx///ve/ASgqKqJr1678+c9/ZsGCBfTq1WuPbX/yySdMnrznRWFhYSFvvvkm06ZNA2DTpk0MHOiesPf7/XTt2pWCgoKI26xt27ZtvPbaa6xatQoRobCwEIBp06Zx0003ceyxx7JhwwZOP/10Vq5cCcCSJUv4+OOPSU9P54YbbmDatGlcdtllVFZWUl1dDcBBBx3E4sWLG/t1Niixk8L3n4I/HfqOjHckxrQL9V3Rt5Z58+Yxb948DjvM1QOWlJSwZs0ajjvuOG6++WZuvfVWzj77bI477rgGt7V582Z69+6927RAIMDkyZO58cYbQ8VKqnu+MxvtUz5dunQhLS2N6667jrPOOouzzz4bgPnz57NixYrQcjt27KC4uBiACRMmkJ6eDsDYsWO59957yc3N5bzzzmPYsGEA+Hw+UlJSKC4uJjMzM6pYopHYdQrffwwDjwR/SrwjMcZESVW5/fbbWbZsGcuWLSMnJ4drr72W/fbbjyVLlnDwwQdz++23c8899zS4rfT09D2e6Z8yZQrDhg3jF7/4RWjagAED2LjRtdoTCAQoKiqiR48eu63n9/sJBoOh8Zrt+v1+Fi1axPnnn8/rr7/O+PHjAQgGg3z22Weh49i0aVPo5N6pU6fQdi699FJmz55Neno6p59+Ou+//35oXkVFBWlpaVF9b9FK3KRQVghbvrGiI2PauMzMzNAVNMDpp5/O9OnTKSkpAVzRztatW8nLyyMjI4PLL7+cm2++maVLl0ZcP9wBBxxATk5OaPyOO+6gqKiIhx9+eLflJkyYwDPPPAPAK6+8wkknnbTHncLgwYNZsWIFFRUVFBUV8d577wHuTqaoqIgzzzyThx9+OFQMdtppp/Hoo4+G1q+ZXtu6devYZ599uPHGG5kwYQJfffUVAAUFBfTu3bvJzVnUJXGLjzZ+DigMPjrekRhj6tGzZ0+OOeYYDjroIM444wweeOABVq5cydixYwHo3Lkzzz33HDk5Odxyyy0kJSWRnJzM448/Drgr/zPOOIO+ffvuUdF81llnsXDhQk455RRyc3O59957GT58OIcf7lo3mDp1Ktdddx3XXnstV1xxBUOHDqVHjx7MnDlzjzgHDhzIRRddxCGHHMKwYcNCxVvFxcVMnDiR8vJyVJWHHnoIgEceeYTrr7+eQw45hEAgwLhx43jiiSf22O5LL73Ec889R3JyMn369OHOO92rXgsWLODMM89soW95F4lUVtaWjRo1SrOzW6AljHfvhM/+CrdtgJSM5m/PmA5q5cqVHHDAAfEOIybKyso48cQT+eSTT/D52tdj6eeddx733Xcf+++//x7zIv3ORGSJqjbYkVniFh99/6lr68gSgjEJKz09nbvvvptNmzbFO5RGqaysZNKkSRETQnMlZvFR5U7I+wKOviHekRhj4uz000+PdwiNlpKSwpVXXhmTbSfmnULuYtfekVUyG2PMbhIzKaxbCEl+GDgm3pEYY0ybkphJYc18lxDSusQ7EmOMaVMSLyns2Aw/fA1DT4l3JMYY0+YkXlLIme9+Djs1vnEYY6LS1FZSzzzzzFA7Q3W58847mT9/flND65ASMylk9oW9D4p3JMaYKNSVFGoahqvLnDlz6NatW73L3HPPPZxyipUahEusR1KrA67rzQPOsa43jWmKt2+DLV+37Db7HAxn3F/n7PCms5OTk+ncuTN9+/Zl2bJlrFixgkmTJrFx40bKy8uZNm0aU6ZMASArK4vs7GxKSko444wzOPbYY/n000/p378/b7zxBunp6Vx99dWcffbZXHDBBWRlZXHVVVfx5ptvUlVVxcsvv8zw4cPJz8/n0ksvpaCggCOPPJJ33nmHJUuWRNVCanuUWHcKuYuhvAiGWtGRMe3F/fffz7777suyZct44IEHWLRoEffee2+ohdHp06ezZMkSsrOzeeSRRygoKNhjG2vWrOH6669n+fLldOvWjVdffTXivnr16sXSpUv5+c9/zoMPPgjA3XffzUknncTSpUs599xzQ/0fdFQxvVMQkfHAXwAf8LSq3l9r/s+A64FqoASYoqor9thQS8l5F8QH+5wQs10Y06HVc0XfWkaPHs2QIUNC44888givvfYaABs3bmTNmjX07Nlzt3WGDBnCyJGuifwjjjiizu40zzvvvNAy//rXvwD4+OOPQ9sfP3483bt3b9HjaWtidqcgIj7gMeAMYAQwWURG1FrsBVU9WFVHAn8E/hyreABXnzBwNKTXX85ojGm7wpuVXrhwIfPnz+ezzz7jyy+/5LDDDtujKWyA1NTU0Gefz1dnN5c1y4Uv097ah2uuWBYfjQZyVHWdqlYCM4GJ4Quoani/fp2A2H37xT/A5i/tUVRj2pn6mr4uKiqie/fuZGRksGrVKv7zn/+0+P6PPfZYZs2aBbgOfrZv397i+2hLYll81B/YGDaeC+zxCrGIXA/8D5ACnBRpQyIyBZgCMGjQoKZFs9a1bW6PohrTvoQ3nZ2ens7ee+8dmjd+/HieeOIJDjnkEPbff3+OOuqoFt//b37zGyZPnsxLL73E8ccfT9++fVu0p7O2JmZNZ4vIhcDpqnqdN34FMFpVI7ZCJyKXestfVd92m9x09qp/wxfPwyXP25NHxjRCR246OxoVFRX4fD78fj+fffYZP//5z+vsEKetaE7T2bG8U8gFBoaNDwDy6ll+JvB4zKIZfpYbjDGmETZs2MBFF11EMBgkJSWFp556Kt4hxVQsk8JiYJiIDAE2AZcAl4YvICLDVHWNN3oWsAZjjGlDhg0bxhdffBHvMFpNzJKCqgZEZCowF/dI6nRVXS4i9wDZqjobmCoipwBVwHag3qIjY0x8qOoefRKbtqm5VQIxfU9BVecAc2pNuzPs87RY7t8Y03xpaWkUFBTQs2dPSwxtnKpSUFBAWlpak7eRWM1cGGMabcCAAeTm5pKfnx/vUEwU0tLSGDBgQJPXt6RgjKlXcnLybm8Qm44tsdo+MsYYUy9LCsYYY0IsKRhjjAmJ2RvNsSIi+cD3jVilF/BjjMJpyxLxuBPxmCExjzsRjxmad9yDVbV3Qwu1u6TQWCKSHc2r3R1NIh53Ih4zJOZxJ+IxQ+sctxUfGWOMCbGkYIwxJiQRksKT8Q4gThLxuBPxmCExjzsRjxla4bg7fJ2CMcaY6CXCnYIxxpgoWVIwxhgT0qGTgoiMF5HVIpIjIrfFO56WIiLTRWSriHwTNq2HiLwrImu8n9296SIij3jfwVcicnj8Im8eERkoIgtEZKWILBeRad70DnvsIpImIotE5EvvmO/2pg8Rkc+9Y35JRFK86aneeI43Pyue8TeHiPhE5AsRecsbT4RjXi8iX4vIMhHJ9qa16t93h00KIuIDHgPOAEYAk0VkRHyjajEzgPG1pt0GvKeqw4D3vHFwxz/MG6YQy97tYi8A/FJVDwCOAq73fqcd+dgrgJNU9VBgJDBeRI4C/gA85B3zduBab/lrge2qOhR4yFuuvZoGrAwbT4RjBjhRVUeGvY/Qun/fqtohB2AsMDds/Hbg9njH1YLHlwV8Eza+Gujrfe4LrPY+/w2YHGm59j4AbwCnJsqxAxnAUmAM7q1Wvzc99LeO69RqrPfZ7y0n8Y69Ccc6AHcCPAl4C5COfsxe/OuBXrWmterfd4e9UwD6AxvDxnO9aR3V3qq6GcD7uZc3vUN+D14RwWHA53TwY/eKUZYBW4F3gbVAoaoGvEXCjyt0zN78IqBn60bcIh4G/hcIeuM96fjHDKDAPBFZIiJTvGmt+vfdkftTiNRFVCI+f9vhvgcR6Qy8CvxCVXfU0xtYhzh2Va0GRopIN+A14IBIi3k/2/0xi8jZwFZVXSIiJ9RMjrBohznmMMeoap6I7AW8KyKr6lk2Jsfdke8UcoGBYeMDgLw4xdIafhCRvgDez63e9A71PYhIMi4hPK+q//ImJ8Sxq2ohsBBXn9JNRGou6sKPK3TM3vyuwLbWjbTZjgEmiMh6YCauCOlhOvYxA6Cqed7PrbgLgNG08t93R04Ki4Fh3hMLKcAlwOw4xxRLs4GrvM9X4crba6Zf6T2pcBRQVHMr2t6IuyX4O7BSVf8cNqvDHruI9PbuEBCRdOAUXOXrAuACb7Hax1zzXVwAvK9egXN7oaq3q+oAVc3C/d++r6qX0YGPGUBEOolIZs1n4DTgG1r77zveFSsxrrQ5E/gWVwb7f/GOpwWP60VgM1CFu1q4FleG+h6wxvvZw1tWcE9hrQW+BkbFO/5mHPexuNvjr4Bl3nBmRz524BDgC++YvwHu9KbvAywCcoCXgVRvepo3nuPN3yfex9DM4z8BeCsRjtk7vi+9YXnNOau1/76tmQtjjDEhHbn4yBhjTCNZUjDGGBNiScEYY0yIJQVjjDEhlhSMMcaEWFIwzSYiKiJ/Chu/WUTuaqFtzxCRCxpestn7udBrfXVBrelZEtYabRTbmdSchhe9/V1az7wyrwXNmiGlJfdhjCUF0xIqgPNEpFe8AwnntZQbrWuB/1bVE5u520m4VnmbKguo74S9Vl0LmjVDZQz2EVEjv0/TTllSMC0hgOs79qbaM2pf6YtIiffzBBH5QERmici3InK/iFwmru+Ar0Vk37DNnCIiH3nLne2t7xORB0RksdeW/H+FbXeBiLyAe6GndjyTve1/IyJ/8KbdiXsx7gkReSCaAxaRn3r7/lJEXhWRDBE5GpgAPOBdxe/rDe94DZx9JCLDw76XR0TkUxFZF/Yd3Q8c562/x/dZRyydxPWxsVhc/wMTvelZ3j6XesPRkfYhIleLyKNh23tLvDaHRKRERO4Rkc+BsSJyhPd7WyIic8OaX7hRRFZ4v4uZ0cRt2qh4v8VnQ/sfgBKgC67Z367AzcBd3rwZwAXhy3o/TwAKcU0BpwKbgLu9edOAh8PWfwd3ATMM9wZ3Gq79+Du8ZVKBbGCIt92dwJAIcfYDNgC9cY1Bvg9M8uYtJMIbodRqojxses+wz78DbqjjeN8Dhnmfx+CaYKhZ7mXvuEYAOWHfy1t1fM9ZQBm73uZ+zJv+e+By73M33Fv8nXBNbad504cB2ZH2AVwNPBo2/hZwgvdZgYu8z8nAp0Bvb/xiYLr3OY9dbxh3i/ffpA1NHzpyK6mmFalrrfRZ4EbciSsai9Vrq0VE1gLzvOlfA+HFOLNUNQisEZF1wHBcuzCHhF1hd8Wd+CqBRar6XYT9HQksVNV8b5/PA+OA16OMN9xBIvI73Em4M65N/92Ia831aOBl2dWSa2rYIq97x7VCRPaOcr9rVXVkrWmn4RqQu9kbTwMG4U7Uj4rISKAa2C/KfYSrxjVACLA/cBCu9U4AH665FXDNcDwvIq/TtO/TtBGWFExLehjXCcw/wqYF8IopxZ1JwitGK8I+B8PGg+z+t1m7LRbFtftyg6rudjL2ij121hFfnW1sN8EM3F3GlyJyNe7qu7YkXB8AtU/iNcKPvzmxCXC+qq7ebaKr7P8BONSLpbyO9UO/I09a2OdydU131+xnuaqOjbCNs3AJdgLwaxE5UHf1fWDaEatTMC1GVbcBs9jVTSK4IqUjvM8TcUUQjXWhiCR59Qz74HqYmgv8XFxT2ojIfuJalqzP58DxItLLqzSdDHzQhHgAMoHN3v4vC5te7M1DVXcA34nIhV6MIiKHNrDd0PqNMBe4wUu6iMhh3vSuwGbvbuQK3JV9pH2sx/XXkCQiA3HNNUeyGugtImO9/SSLyIEikgQMVNUFuI5xau6eTDtkScG0tD8B4U8hPYU7ES/ClanXdRVfn9W4k/fbwM9UtRx4GlgBLBX3yOjfaODO1yuquh3XBPOXwFJVfaO+dTz7i0hu2HAh8GtcknkXCO8IZSZwi1fhuy8uYVwrIjUtX05sYF9fAQGvAjuqimbgt7hk+5X3XfzWm/5X4CoR+Q+u6Kjmu6+9j0+A73DFdg/i7vb2oO5JpwuAP3jHswxXPOYDnhORr3Etuj6kru8H0w5ZK6nGGGNC7E7BGGNMiCUFY4wxIZYUjDHGhFhSMMYYE2JJwRhjTIglBWOMMSGWFIwxxoT8f/o2jBxNN312AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb1f5f2ba8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use these cells to see how well you can use the training \n",
    "# decomposition to predict on test data\n",
    "num_latent_feats = np.arange(5,505,5)\n",
    "sum_errs_test = []\n",
    "sum_errs_train = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    ### TESTING DATA\n",
    "    # restructure with k latent features\n",
    "    s_test, u_test, vt_test = np.diag(s_train[:k]), u_test_subset[:, :k], vt_test_subset[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_test, s_test), vt_test))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_test[:20], user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs_test.append(err)\n",
    "    \n",
    "    ### TRAINING DATA\n",
    "    # bring in the previous training data for comparison\n",
    "    s_new, u_new, vt_new = np.diag(s_train[:k]), u_train[:, :k], vt_train[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_train, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs_train.append(err)\n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs_test)/df_test.shape[0]);\n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs_train)/df_train.shape[0]);\n",
    "plt.legend(labels=['test (20 users)','training'])\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`6.` Use the cell below to comment on the results you found in the previous question. Given the circumstances of your results, discuss what you might do to determine if the recommendations you make with any of the above recommendation systems are an improvement to how users currently find articles? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this context, there are several hundred articles that are NOT read by a user and only a few that are. There are no ratings, simply binary flags for the presence of an interaction between the user and the article. Singular Value Decomposition does not provide a great deal of insight in this case. In fact, SVD has a marginal decrease in its performance as more latent features are used in the prediction because those same latent features helped select those same articles as UNREAD by that particular user during training.**\n",
    "\n",
    "**Due to the high number of unread articles in the dataset, accuracy is also a poor assessment of the strength of the model's performance. The graph shows a marginal decline in testing on the model because as more latent features are included in the model, the more likely the model is to predict an article as UNREAD (its training state), but our entire test set is likely NEW articles read by the users.**\n",
    "\n",
    "**Due to the low number of predictable users (both in the training and testing set) and the problems with train and test splitting mentioned above, it is difficult to get a solid measure of accuracy.**\n",
    "\n",
    "**Looking ahead, to measure the effectiveness of any of the recommendation systems above, I would implement a feedback system for users where they could score the utility of the article. This would allow the system to move away from a binary scoring system by developing user profiles (more complete preferences and predictions) in regards to what articles they find useful. This would improve the effect of the latent features in SVD and provide better user interaction metrics moving forward.**\n",
    "\n",
    "**There could also be random sampling and feedback to allow users to inform the process - these could be formal surveys (which could provide feedback to all types of recommendations), or monitoring how often a user needs to change their search preferences to find an article before they interact with it (which would help improve content-based recommendations), or monitor user similarity over time to see if users become more of less similar based on our recommendations (which informs the collaborative filtering).**\n",
    "\n",
    "**One way to implement, formalize, and measure how the methods above compare to the current system would be to implement a 60-day A/B experiment where the A group continues to find articles their usual way and the B group receives recommendations according to the algorithms above (collaborative filtering, content-based filtering). The two groups could then be compared according to a few metrics: time-spent on the site, number of interactions per month. Throughout this experiment, additional data could be collected regarding users preference for recommendation types, affinity with other users, etc. At the end of the 60-day experiment, depending on the results, the methods could be further adapted with the data gathered or rolled out to the entire community.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='conclusions'></a>\n",
    "### Extras\n",
    "Using your workbook, you could now save your recommendations for each user, develop a class to make new predictions and update your results, and make a flask app to deploy your results.  These tasks are beyond what is required for this project.  However, from what you learned in the lessons, you certainly capable of taking these tasks on to improve upon your work here!\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "> Congratulations!  You have reached the end of the Recommendations with IBM project! \n",
    "\n",
    "\n",
    "## Directions to Submit\n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Recommendations_with_IBM.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
